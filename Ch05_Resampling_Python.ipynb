{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac385101",
   "metadata": {},
   "source": [
    "# Class Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d865134",
   "metadata": {},
   "source": [
    "## In class activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194cc60b",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "#import statsmodels.api as sm\n",
    "from plotnine import *\n",
    "import statsmodels.formula.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                        summarize ,\n",
    "                        poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786799d",
   "metadata": {},
   "source": [
    "### Ames House Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f933c5",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bd901",
   "metadata": {},
   "source": [
    "Let's revisit the AmesHousing data.  As we did in the previous class, I will split the data into before 2008 and after.  The data up to 2008 will be the training data and after 2008 will be the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c2a208",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8516aa",
   "metadata": {},
   "source": [
    "* For the regression model fit, use bootstrap to compare the standard error estimates to the model based estimates.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2fafbb",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      np.log(SalePrice)   R-squared:                       0.823\n",
      "Model:                            OLS   Adj. R-squared:                  0.822\n",
      "Method:                 Least Squares   F-statistic:                     506.8\n",
      "Date:                Sat, 03 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        13:10:19   Log-Likelihood:                 475.56\n",
      "No. Observations:                1318   AIC:                            -925.1\n",
      "Df Residuals:                    1305   BIC:                            -857.7\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Intercept                             -12.4592     36.460     -0.342      0.733     -83.986      59.068\n",
      "Q('Year Built')                         0.0089      0.019      0.476      0.634      -0.028       0.046\n",
      "Q('Year Remod/Add')                     0.0105      0.018      0.572      0.567      -0.026       0.047\n",
      "Q('Total Bsmt SF')                      0.0004   2.75e-05     13.418      0.000       0.000       0.000\n",
      "Q('1st Flr SF')                         0.0002   2.78e-05      6.256      0.000       0.000       0.000\n",
      "Q('Gr Liv Area')                        0.0006   4.07e-05     14.943      0.000       0.001       0.001\n",
      "Q('Full Bath')                         -0.0392      0.013     -3.118      0.002      -0.064      -0.015\n",
      "Q('TotRms AbvGrd')                      0.0121      0.009      1.391      0.165      -0.005       0.029\n",
      "Q('Garage Area')                       -0.0083      0.002     -5.434      0.000      -0.011      -0.005\n",
      "Q('Year Built'):Q('Year Remod/Add') -3.884e-06   9.42e-06     -0.412      0.680   -2.24e-05    1.46e-05\n",
      "Q('Total Bsmt SF'):Q('1st Flr SF')  -1.334e-07   1.29e-08    -10.349      0.000   -1.59e-07   -1.08e-07\n",
      "Q('Gr Liv Area'):Q('TotRms AbvGrd') -2.294e-05   4.49e-06     -5.109      0.000   -3.17e-05   -1.41e-05\n",
      "Q('Garage Area'):Q('Year Built')     4.353e-06   7.76e-07      5.613      0.000    2.83e-06    5.87e-06\n",
      "==============================================================================\n",
      "Omnibus:                      209.482   Durbin-Watson:                   1.623\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1023.379\n",
      "Skew:                          -0.652   Prob(JB):                    5.97e-223\n",
      "Kurtosis:                       7.115   Cond. No.                     3.35e+10\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.35e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "formula = \"np.log(SalePrice) ~ Q('Year Built') + Q('Year Remod/Add') + Q('Total Bsmt SF') + Q('1st Flr SF') + Q('Gr Liv Area') + Q('Full Bath') + Q('TotRms AbvGrd') + Q('Garage Area') + Q('Year Built'):Q('Year Remod/Add') + Q('Total Bsmt SF'):Q('1st Flr SF') + Q('Gr Liv Area'):Q('TotRms AbvGrd') + Q('Garage Area'):Q('Year Built')\"\n",
    "lmfit_2008 =  sm.ols(formula, data = ames_raw_2008).fit() # use ames_raw_2008\n",
    "print(lmfit_2008.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8764f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Standard Errors:\n",
      "Intercept                              2.159540e+00\n",
      "Q('Year Built')                        1.106017e-03\n",
      "Q('Year Remod/Add')                    1.090821e-03\n",
      "Q('Total Bsmt SF')                     4.771165e-06\n",
      "Q('1st Flr SF')                        4.104099e-06\n",
      "Q('Gr Liv Area')                       2.514337e-06\n",
      "Q('Full Bath')                         7.133023e-04\n",
      "Q('TotRms AbvGrd')                     6.163576e-04\n",
      "Q('Garage Area')                       9.441318e-05\n",
      "Q('Year Built'):Q('Year Remod/Add')    5.586422e-07\n",
      "Q('Total Bsmt SF'):Q('1st Flr SF')     5.069290e-09\n",
      "Q('Gr Liv Area'):Q('TotRms AbvGrd')    3.517164e-07\n",
      "Q('Garage Area'):Q('Year Built')       4.800036e-08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_se(df, n_bootstraps=1000):\n",
    "    bootstraps_se = []\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Sample with replacement\n",
    "        sample = df.sample(n=len(df), replace=True)\n",
    "        \n",
    "        # Fit the model on the bootstrap sample\n",
    "        model = sm.ols(formula, data=sample).fit()\n",
    "        \n",
    "        # Store the standard errors of the coefficients\n",
    "        bootstraps_se.append(model.bse)\n",
    "    \n",
    "    return pd.DataFrame(bootstraps_se)\n",
    "\n",
    "# Perform bootstrapping\n",
    "bootstraps_se = bootstrap_se(ames_raw_2009)\n",
    "\n",
    "# Calculate the standard errors from the bootstrap samples\n",
    "bootstrap_standard_errors = bootstraps_se.std()\n",
    "\n",
    "print(\"Bootstrap Standard Errors:\")\n",
    "print(bootstrap_standard_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8bb5d",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Bootstrap standard errors are generally smaller than model-based errors, suggesting a more optimistic assessment of coefficient precision from the bootstrap method.\n",
    "~~~\n",
    "\n",
    "\n",
    "* Use cross validation  to decide which model has a good predictive accuracy.  Does the result hold true for the prediction of future data?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2206cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Average MSE: 0.036111120652910875\n",
      "Model 2 Average MSE: 0.029709499319593526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "mse_model1 = []\n",
    "mse_model2 = []\n",
    "\n",
    "for train_index, test_index in kf.split(ames_raw_2008):\n",
    "    train_data, test_data = ames_raw_2008.iloc[train_index], ames_raw_2008.iloc[test_index]\n",
    "    \n",
    "    # Model 1\n",
    "    formula1 = \"np.log(SalePrice) ~ Q('Year Built') + Q('Year Remod/Add') + Q('Total Bsmt SF') + Q('1st Flr SF') + Q('Gr Liv Area') + Q('Full Bath') + Q('TotRms AbvGrd') + Q('Garage Area')\"\n",
    "    model1 = sm.ols(formula1, data=train_data).fit()\n",
    "    predictions1 = model1.predict(test_data)\n",
    "    predictions1 = predictions1.fillna(predictions1.mean())\n",
    "    mse_model1.append(mean_squared_error(np.log(test_data['SalePrice']), predictions1))\n",
    "    \n",
    "    # Model 2\n",
    "    formula2 = \"np.log(SalePrice) ~ Q('Year Built') + Q('Year Remod/Add') + Q('Total Bsmt SF') + Q('1st Flr SF') + Q('Gr Liv Area') + Q('Full Bath') + Q('TotRms AbvGrd') + Q('Garage Area') + Q('Year Built'):Q('Year Remod/Add') + Q('Total Bsmt SF'):Q('1st Flr SF') + Q('Gr Liv Area'):Q('TotRms AbvGrd') + Q('Garage Area'):Q('Year Built')\"\n",
    "    model2 = sm.ols(formula2, data=train_data).fit()\n",
    "    predictions2 = model2.predict(test_data)\n",
    "    predictions2 = predictions2.fillna(predictions2.mean())\n",
    "    mse_model2.append(mean_squared_error(np.log(test_data['SalePrice']), predictions2))\n",
    "\n",
    "# 计算平均 MSE\n",
    "avg_mse_model1 = np.mean(mse_model1)\n",
    "avg_mse_model2 = np.mean(mse_model2)\n",
    "\n",
    "print(f\"Model 1 Average MSE: {avg_mse_model1}\")\n",
    "print(f\"Model 2 Average MSE: {avg_mse_model2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee392923",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Based on the average MSE, model2 which has interaction terms performs better. This is also true for the test data.\n",
    "~~~\n",
    "\n",
    "\n",
    "* Using `knn.reg` fit KNN regression model.  Use cross validation to decide which K to use.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b13b86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")\n",
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54c21c64",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = ames_raw_2008[['Year Built', 'Year Remod/Add', 'Total Bsmt SF', '1st Flr SF', \n",
    "                      'Gr Liv Area', 'Full Bath', 'TotRms AbvGrd', 'Garage Area']].dropna()\n",
    "y_train = np.log(ames_raw_2008['SalePrice']).loc[X_train.index]  # Match the labels with the filtered rows\n",
    "X_test = ames_raw_2009[['Year Built', 'Year Remod/Add', 'Total Bsmt SF', '1st Flr SF', \n",
    "                      'Gr Liv Area', 'Full Bath', 'TotRms AbvGrd', 'Garage Area']].dropna()\n",
    "y_test = np.log(ames_raw_2009['SalePrice']).loc[X_test.index]  # Match the labels with the filtered rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f37fc7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1318, 8)\n",
      "(1318,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Check the number of rows and columns in X_train\n",
    "print(y_train.shape)  # Check the number of rows in y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a177a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors': np.arange(1, 31)}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116dea8",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Best K = 12.\n",
    "~~~\n",
    "\n",
    "\n",
    "* Which model performs better on your training data?  Which model performs better in your future prediction?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65117052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Train MSE: 0.03473977799856296\n",
      "Model 1 Test MSE: 0.039508522888133044\n",
      "Model 2 Train MSE: 0.028440592361156397\n",
      "Model 2 Test MSE: 0.03392795358838713\n"
     ]
    }
   ],
   "source": [
    "# Split again\n",
    "X_train = ames_raw_2008.drop(columns=['SalePrice'])\n",
    "y_train = np.log(ames_raw_2008['SalePrice'])\n",
    "X_test = ames_raw_2009.drop(columns=['SalePrice'])\n",
    "y_test = np.log(ames_raw_2009['SalePrice'])\n",
    "\n",
    "# Model 1\n",
    "model1 = sm.ols(formula1, data=ames_raw_2008).fit()\n",
    "train_predictions1 = model1.predict(X_train)\n",
    "train_predictions1 = train_predictions1.fillna(train_predictions1.mean())\n",
    "test_predictions1 = model1.predict(X_test)\n",
    "test_predictions1 = test_predictions1.fillna(test_predictions1.mean())\n",
    "\n",
    "# Model 1 MSE\n",
    "train_mse_model1 = mean_squared_error(y_train, train_predictions1)\n",
    "test_mse_model1 = mean_squared_error(y_test, test_predictions1)\n",
    "\n",
    "# Model 2\n",
    "model2 = sm.ols(formula2, data=ames_raw_2008).fit()\n",
    "train_predictions2 = model2.predict(X_train)\n",
    "train_predictions2 = train_predictions2.fillna(train_predictions2.mean())\n",
    "test_predictions2 = model2.predict(X_test)\n",
    "test_predictions2 = test_predictions2.fillna(test_predictions2.mean())\n",
    "\n",
    "# Model 2 MSE\n",
    "train_mse_model2 = mean_squared_error(y_train, train_predictions2)\n",
    "test_mse_model2 = mean_squared_error(y_test, test_predictions2)\n",
    "\n",
    "print(f\"Model 1 Train MSE: {train_mse_model1}\")\n",
    "print(f\"Model 1 Test MSE: {test_mse_model1}\")\n",
    "print(f\"Model 2 Train MSE: {train_mse_model2}\")\n",
    "print(f\"Model 2 Test MSE: {test_mse_model2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b41a25c",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.035024248033121826\n",
      "Test MSE: 0.047903293649576184\n"
     ]
    }
   ],
   "source": [
    "# KNN with best parameter\n",
    "best_knn = KNeighborsRegressor(n_neighbors=grid_search.best_params_['n_neighbors'])\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = best_knn.predict(X_train)\n",
    "test_predictions = best_knn.predict(X_test)\n",
    "\n",
    "# Train MSE\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "\n",
    "# Test MSE\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf13891",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Model 1 Train MSE: 0.03473977799856296\n",
    "Model 1 Test MSE: 0.039508522888133044\n",
    "Model 2 Train MSE: 0.028440592361156397\n",
    "Model 2 Test MSE: 0.03392795358838713\n",
    "KNN Train MSE: 0.035024248033121826\n",
    "KNN Test MSE: 0.047903293649576184\n",
    "Therefore, Model 2 (Linear regression with interaction terms) performs better on both train and test set.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b49db5",
   "metadata": {},
   "source": [
    "## Problem Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e310f",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "\n",
    "We will now investigate numerically the probability that a bootstrap sample of size n = 100 contains the jth observation. Here j = 4. We first create an array store with values that will subsequently\n",
    "be overwritten using the function np.empty(). We then repeatedly create bootstrap samples, and each time we record whether or not the fifth observation is contained in the bootstrap\n",
    "sample.\n",
    "\n",
    "We will investigate numerically the probability that a bootstrap sample of size n = 100 contains the jth observation. Here j = 4. We repeatedly create bootstrap samples, and each time\n",
    "we record whether or not the fourth observation is contained in the bootstrap sample.\n",
    "\n",
    "Here is the code to get you going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "275e75fd",
   "metadata": {
    "Rmd_chunk_options": "echo =TRUE,eval=FALSE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6362"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng (10)\n",
    "store = np.empty (10000)\n",
    "for i in range (10000):\n",
    "    store[i] = np.sum(rng.choice(100, 100, replace=True) == 4) > 0\n",
    "\n",
    "\n",
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96d784",
   "metadata": {},
   "source": [
    "Comment on the results obtained.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a4875",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Although the bootstrap sample is obtained from the original sample by replacement, each observation is equally likely to be selected in each sample, but not every observation will appear in every bootstrap sample.\n",
    "The code shows that the probability that bootstrap sample contains certain value is 63.62%. That's in line with the mathematical calcualtion: lim(n->infinity)(1-(1/n)^n)=0.63.\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9da176",
   "metadata": {},
   "source": [
    "### CV\n",
    "\n",
    "We will now perform cross-validation on a simulated data set.\n",
    "(a) Generate a simulated data set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "269de067",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo =TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7051ad7",
   "metadata": {},
   "source": [
    "In this data set, what is n and what is p? Write out the model\n",
    "used to generate the data in equation form.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab751",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "n = 100, p = 2.\n",
    "y = β0 + β1x + β2x^2 +error = x - 2x^2 + error\n",
    "~~~\n",
    "\n",
    "\n",
    "(b) Create a scatterplot of X against Y . Comment on what you find.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f195ab3",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatterplot\n",
    "plt.scatter(x, y, alpha = 0.85)\n",
    "plt.title(\"Scatter Plot of X against Y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef692fff",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "The plot shows the distribution is along y = x - 2x^2.\n",
    "~~~\n",
    "\n",
    "(c) Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:\n",
    "\n",
    "i.   $Y = \\beta_0 + \\beta_1X + \\epsilon$\n",
    "ii.  $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon$\n",
    "iii. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$\n",
    "iv.  $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\beta_4X^4 + \\epsilon$.\n",
    "\n",
    "Note you may find it helpful to use the `data.frame()` function\n",
    "to create a single data set containing both $X$ and $Y$ .\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45208594",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 LOOCV MSE: 5.772817045970774\n",
      "Model 2 LOOCV MSE: 1.1563879346405441\n",
      "Model 3 LOOCV MSE: 1.1903554702081685\n",
      "Model 4 LOOCV MSE: 1.1865709751492126\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Generate data\n",
    "x = np.random.normal(size=100)\n",
    "y = x - 2 * x**2 + np.random.normal(size=100)\n",
    "X = np.vstack([x, x**2, x**3, x**4]).T\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=['X', 'X2', 'X3', 'X4'])\n",
    "df['Y'] = y\n",
    "\n",
    "# LOOCV\n",
    "loo = LeaveOneOut()\n",
    "models = ['Y ~ X', 'Y ~ X + X2', 'Y ~ X + X2 + X3', 'Y ~ X + X2 + X3 + X4']\n",
    "loocv_mse = []\n",
    "\n",
    "for model_formula in models:\n",
    "    mse_list = []\n",
    "    for train_index, test_index in loo.split(df):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        model = sm.OLS.from_formula(model_formula, data=train).fit()\n",
    "        y_pred = model.predict(test)\n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(test['Y'], y_pred)\n",
    "        mse_list.append(mse)\n",
    "    # Average MSE\n",
    "    loocv_mse.append(np.mean(mse_list))\n",
    "\n",
    "for i, mse in enumerate(loocv_mse, start=1):\n",
    "    print(f\"Model {i} LOOCV MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dae8c9",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(d) Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fcf9ba9",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 LOOCV MSE: 6.260764331604614\n",
      "Model 2 LOOCV MSE: 0.9142897072803663\n",
      "Model 3 LOOCV MSE: 0.9268768781648802\n",
      "Model 4 LOOCV MSE: 0.8669116865881081\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generate data\n",
    "x = np.random.normal(size=100)\n",
    "y = x - 2 * x**2 + np.random.normal(size=100)\n",
    "X = np.vstack([x, x**2, x**3, x**4]).T\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=['X', 'X2', 'X3', 'X4'])\n",
    "df['Y'] = y\n",
    "\n",
    "# LOOCV\n",
    "loo = LeaveOneOut()\n",
    "models = ['Y ~ X', 'Y ~ X + X2', 'Y ~ X + X2 + X3', 'Y ~ X + X2 + X3 + X4']\n",
    "loocv_mse = []\n",
    "\n",
    "for model_formula in models:\n",
    "    mse_list = []\n",
    "    for train_index, test_index in loo.split(df):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        model = sm.OLS.from_formula(model_formula, data=train).fit()\n",
    "        y_pred = model.predict(test)\n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(test['Y'], y_pred)\n",
    "        mse_list.append(mse)\n",
    "    # Average MSE\n",
    "    loocv_mse.append(np.mean(mse_list))\n",
    "\n",
    "for i, mse in enumerate(loocv_mse, start=1):\n",
    "    print(f\"Model {i} LOOCV MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c1120",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "The results are different. I think the difference is due to the change in samples. Because the n = 100, which is a quite small sample size, we would expect high variance between different samples.\n",
    "~~~\n",
    "\n",
    "(e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301a74c",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Model 2 has the smallest LOOCV error, which is in line with my expectation because the true distribution is also a second-order polynomial.\n",
    "~~~\n",
    "\n",
    "\n",
    "(f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d84ba43e",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y ~ X Coefficients and P-values:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.9443      0.235     -8.263      0.000      -2.411      -1.477\n",
      "X              1.2736      0.241      5.279      0.000       0.795       1.752\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "Y ~ X + X2 Coefficients and P-values:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2005      0.139     -1.444      0.152      -0.476       0.075\n",
      "X              0.8496      0.111      7.641      0.000       0.629       1.070\n",
      "X2            -1.8796      0.096    -19.560      0.000      -2.070      -1.689\n",
      "==============================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Generate data\n",
    "x = np.random.normal(size=100)\n",
    "y = x - 2 * x**2 + np.random.normal(size=100)\n",
    "X = np.vstack([x, x**2, x**3, x**4]).T\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=['X', 'X2', 'X3', 'X4'])\n",
    "df['Y'] = y\n",
    "\n",
    "# Define models\n",
    "models = ['Y ~ X', 'Y ~ X + X2', 'Y ~ X + X2 + X3', 'Y ~ X + X2 + X3 + X4']\n",
    "\n",
    "# Fit models and print coefficients and p-values\n",
    "for model_formula in models[:2]:\n",
    "    model = sm.ols(model_formula, data=df).fit()\n",
    "    print(f\"{model_formula} Coefficients and P-values:\")\n",
    "    print(model.summary().tables[1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "421efe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y ~ X + X2 + X3 Coefficients and P-values:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2021      0.141     -1.436      0.154      -0.482       0.077\n",
      "X              0.8351      0.201      4.149      0.000       0.436       1.235\n",
      "X2            -1.8773      0.100    -18.743      0.000      -2.076      -1.678\n",
      "X3             0.0066      0.076      0.086      0.931      -0.145       0.158\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "Y ~ X + X2 + X3 + X4 Coefficients and P-values:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1170      0.163     -0.716      0.476      -0.441       0.207\n",
      "X              0.7462      0.219      3.405      0.001       0.311       1.181\n",
      "X2            -2.1014      0.241     -8.736      0.000      -2.579      -1.624\n",
      "X3             0.0515      0.088      0.584      0.560      -0.123       0.226\n",
      "X4             0.0614      0.060      1.025      0.308      -0.058       0.180\n",
      "==============================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit models and print coefficients and p-values\n",
    "for model_formula in models[2:4]:\n",
    "    model = sm.ols(model_formula, data=df).fit()\n",
    "    print(f\"{model_formula} Coefficients and P-values:\")\n",
    "    print(model.summary().tables[1])  # Print the summary table of coefficients and p-values\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea7d2f",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "The p-value of X3 and X4 is greater than 0.05, which means their coefficients are not statistical significance. Therefore, we can reject the Null and say the coefficicents of X3 and X4 is 0. This is in line with the cross-validation results that Model 2 is the optimal model.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02963416",
   "metadata": {},
   "source": [
    "### Default 1\n",
    "\n",
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.\n",
    "\n",
    "(a) Fit a logistic regression model that uses income and balance to predict default.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75995a81",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "default = load_data('Default')\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bd408b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['default', 'student', 'balance', 'income'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db00187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.180484\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 7000\n",
      "Model:                          Logit   Df Residuals:                     6998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 03 Feb 2024   Pseudo R-squ.:                 -0.2009\n",
      "Time:                        18:29:05   Log-Likelihood:                -1263.4\n",
      "converged:                       True   LL-Null:                       -1052.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "balance        0.0004   8.32e-05      4.910      0.000       0.000       0.001\n",
      "income        -0.0001   4.26e-06    -28.753      0.000      -0.000      -0.000\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use LabelEncoder to binarize the 'default' column\n",
    "label_encoder = LabelEncoder()\n",
    "default['default'] = label_encoder.fit_transform(default['default'])\n",
    "\n",
    "# Prepare the data\n",
    "X = default[['balance', 'income']]\n",
    "y = default['default']\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Fit the logistic regression model using statsmodels\n",
    "logit_fit = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "print(logit_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf78636",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "i. Split the sample set into a training set and a validation set.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b5e79ce",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d6cd6",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "ii. Fit a multiple logistic regression model using only the training observations.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4933acb7",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.180484\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 7000\n",
      "Model:                          Logit   Df Residuals:                     6998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 03 Feb 2024   Pseudo R-squ.:                 -0.2009\n",
      "Time:                        18:54:53   Log-Likelihood:                -1263.4\n",
      "converged:                       True   LL-Null:                       -1052.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "balance        0.0004   8.32e-05      4.910      0.000       0.000       0.001\n",
      "income        -0.0001   4.26e-06    -28.753      0.000      -0.000      -0.000\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_fit1 = sm.Logit(y_train, X_train).fit()\n",
    "print(logit_fit1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e17ef7",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2337c08a",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Predict the posterior probabilities of default\n",
    "y_validation_post_probs = logit_fit1.predict(X_validation)\n",
    "\n",
    "# Classify individuals\n",
    "y_validation_pred = (y_validation_post_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db2665",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b9bbe22",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error: 0.030333333333333323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "validation_set_error = 1 - validation_accuracy\n",
    "print(f\"Validation Set Error: {validation_set_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2e7e5",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "021da8ff",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179075\n",
      "         Iterations 8\n",
      "Validation Set Error: 0.02949999999999997\n"
     ]
    }
   ],
   "source": [
    "# Time 1\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "logit_fit2 = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Predict the posterior probabilities of default\n",
    "y_validation_post_probs = logit_fit2.predict(X_validation)\n",
    "\n",
    "# Classify individuals\n",
    "y_validation_pred = (y_validation_post_probs > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "validation_set_error = 1 - validation_accuracy\n",
    "print(f\"Validation Set Error: {validation_set_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7ff73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.178395\n",
      "         Iterations 8\n",
      "Validation Set Error: 0.030750000000000055\n"
     ]
    }
   ],
   "source": [
    "# Time 2\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "logit_fit3 = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Predict the posterior probabilities of default\n",
    "y_validation_post_probs = logit_fit3.predict(X_validation)\n",
    "\n",
    "# Classify individuals\n",
    "y_validation_pred = (y_validation_post_probs > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "validation_set_error = 1 - validation_accuracy\n",
    "print(f\"Validation Set Error: {validation_set_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "503d0588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176113\n",
      "         Iterations 8\n",
      "Validation Set Error: 0.032200000000000006\n"
     ]
    }
   ],
   "source": [
    "# Time 3\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "logit_fit4 = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Predict the posterior probabilities of default\n",
    "y_validation_post_probs = logit_fit4.predict(X_validation)\n",
    "\n",
    "# Classify individuals\n",
    "y_validation_pred = (y_validation_post_probs > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "validation_set_error = 1 - validation_accuracy\n",
    "print(f\"Validation Set Error: {validation_set_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2108a59",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "It's interesting to see that as I split less data into training set, the error rate of validation set slightly increases.\n",
    "~~~\n",
    "\n",
    "\n",
    "(d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0087016a",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.126547\n",
      "         Iterations 9\n",
      "Validation Set Error: 0.036666666666666625\n"
     ]
    }
   ],
   "source": [
    "# Convert 'student' to a dummy variable\n",
    "default['student_dummy'] = label_encoder.fit_transform(default['student'])\n",
    "\n",
    "# Include 'student_dummy' in the features\n",
    "X = default[['balance', 'income', 'student_dummy']]\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "logit_fit5 = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Predict the posterior probabilities of default\n",
    "y_validation_post_probs = logit_fit5.predict(X_validation)\n",
    "\n",
    "# Classify individuals\n",
    "y_validation_pred = (y_validation_post_probs > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "validation_set_error = 1 - validation_accuracy\n",
    "print(f\"Validation Set Error: {validation_set_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb222e",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "The error rate slightly increases after including the dummy variable 'student', which indicates that adding student status as a predictor does not improve the model's predictive accuracy for default and might even introduce some noise or unnecessary complexity.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2e117",
   "metadata": {},
   "source": [
    "### Default 2\n",
    "\n",
    "We continue to consider the use of a logistic regression model to\n",
    "predict the probability of default using income and balance on the\n",
    "Default data set. In particular, we will now compute estimates for the\n",
    "standard errors of the income and balance logistic regression coefficients\n",
    "in two different ways: (1) using the bootstrap, and (2) using the\n",
    "standard formula for computing the standard errors in the sm.GLM()\n",
    "function. Do not forget to set a random seed before beginning your\n",
    "analysis.\n",
    "\n",
    "(a) Using the `summarize()` and `sm.GLM()` functions, determine the\n",
    "estimated standard errors for the coefficients associated with\n",
    "income and balance in a multiple logistic regression model that\n",
    "uses both predictors.\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9e48b55",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1734.6\n",
      "Date:                Sat, 03 Feb 2024   Deviance:                       3469.1\n",
      "Time:                        19:30:20   Pearson chi2:                 3.87e+04\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):           -0.05638\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "balance        0.0004   7.03e-05      5.797      0.000       0.000       0.001\n",
      "income        -0.0001    3.7e-06    -34.025      0.000      -0.000      -0.000\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(100)\n",
    "\n",
    "# Prepare the data\n",
    "X = default[['balance', 'income']]\n",
    "y = default['default']\n",
    "\n",
    "# Logistic regression\n",
    "logit_fit6 = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
    "print(logit_fit6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabf728",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(b) Write a function, `boot_fn()`, that takes as input the Default data\n",
    "set as well as an index of the observations, and that outputs\n",
    "the coefficient estimates for income and balance in the multiple\n",
    "logistic regression model.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "150d3446",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Subset the data to the specified index\n",
    "    data_subset = data.iloc[index]\n",
    "    \n",
    "    # Prepare the predictors and response\n",
    "    X_subset = data_subset[['balance', 'income']]\n",
    "    y_subset = data_subset['default']\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    model = sm.GLM(y_subset, X_subset, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Extract and return the coefficients for income and balance\n",
    "    return result.params['income'], result.params['balance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9f690",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(c) Following the bootstrap example in the lab, use your `boot_fn()`\n",
    "function to estimate the standard errors of the logistic regression\n",
    "coefficients for income and balance.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "771a1fca",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Standard Error for balance coefficient: 6.948859431285401e-05\n",
      "Bootstrap Standard Error for income coefficient: 3.996186842042876e-06\n"
     ]
    }
   ],
   "source": [
    "# Number of bootstrap samples\n",
    "n_bootstraps = 1000\n",
    "\n",
    "# Arrays to store bootstrap estimates\n",
    "boot_balance_coeffs = np.zeros(n_bootstraps)\n",
    "boot_income_coeffs = np.zeros(n_bootstraps)\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    # Generate bootstrap sample indices\n",
    "    boot_indices = np.random.choice(range(len(X)), size=len(X), replace=True)\n",
    "\n",
    "    # Calculate coefficients for this bootstrap sample\n",
    "    income_coef, balance_coef = boot_fn(default, boot_indices)\n",
    "    boot_income_coeffs[i] = income_coef\n",
    "    boot_balance_coeffs[i] = balance_coef\n",
    "\n",
    "# Calculate standard errors from bootstrap coefficient distributions\n",
    "balance_se = np.std(boot_balance_coeffs, ddof=1)\n",
    "income_se = np.std(boot_income_coeffs, ddof=1)\n",
    "\n",
    "print(f\"Bootstrap Standard Error for balance coefficient: {balance_se}\")\n",
    "print(f\"Bootstrap Standard Error for income coefficient: {income_se}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f2e13",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(d) Comment on the estimated standard errors obtained using the `sm.GLM()` function and using the bootstrap.\n",
    "\n",
    "Your answer:\n",
    "\n",
    "~~~\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "balance        0.0004   7.03e-05      5.797      0.000       0.000       0.001\n",
    "income        -0.0001    3.7e-06    -34.025      0.000      -0.000      -0.000\n",
    "==============================================================================\n",
    "\n",
    "Bootstrap Standard Error for balance coefficient: 6.948859431285401e-05\n",
    "Bootstrap Standard Error for income coefficient: 3.996186842042876e-06\n",
    "\n",
    "Based on the results of two methods, they are close to each other. This similarity indicates that the bootstrap method provides a reliable estimate of the standard errors, which aligns well with the theoretical standard errors calculated directly from the logistic regression model.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e99194",
   "metadata": {},
   "source": [
    "### Boston housing data set\n",
    "\n",
    "We will now consider the Boston housing data set, from the ISLR library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e0c713d",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Boston = load_data(\"Boston\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478a17a",
   "metadata": {},
   "source": [
    "(a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate $\\hat{\\mu}$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ac30b1b",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   lstat  medv  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f8198cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "93a4beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "mu_hat = Boston['medv'].mean()\n",
    "print(mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c227ec3",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(b) Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result.\n",
    "Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1caaf8fc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4088611474975351\n"
     ]
    }
   ],
   "source": [
    "se_mu_hat = Boston['medv'].std() / np.sqrt(len(Boston))\n",
    "print(se_mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446e733",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(c) Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (b)?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c0a9cbf",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf56fb8",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(d) Based on your bootstrap estimate from (c), provide a 95 % confidence\n",
    "interval for the mean of medv. Compare it to the results\n",
    "obtained by using `Boston['medv'].std()` and the two standard\n",
    "error rule (3.9).\n",
    "Hint: You can approximate a 95% confidence interval using the formula $[\\hat{\\mu} − 2SE(\\hat{\\mu}), \\hat{\\mu} + 2SE(\\hat{\\mu})]$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59be24cc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a99c5",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(e) Based on this data set, provide an estimate, $\\hat{\\mu}_{med}$, for the median value of medv in the population.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce645b44",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927aa002",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(f) We now would like to estimate the standard error of $\\hat{\\mu}_{med}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0221e97a",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90e963",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "(g) Based on this data set, provide an estimate for the tenth percentile\n",
    "of medv in Boston census tracts. Call this quantity $\\hat{\\mu}_{0.1}$.\n",
    "(You can use the `np.percentile()` function.)\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dca83bcb",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a298b56",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "(h) Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$. Comment on your findings.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56248d00",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f070ead",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8173b4",
   "metadata": {},
   "source": [
    "## Additional Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6174ae",
   "metadata": {},
   "source": [
    "### Cross Validation for Predictive Modeling Platforms in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfdcf96",
   "metadata": {},
   "source": [
    "#### scikit-learn\n",
    "\n",
    "Using platforms like scikit-learn is helpful for things such as cross validation.\n",
    "There are variants of CV implemented to be used off the shelf\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "There are many metrics you can choose from\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "753aa0f5",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_comp=ames_raw.loc[:,[\"SalePrice\",\"Gr Liv Area\",\"Lot Area\",\"Total Bsmt SF\"]].dropna()\n",
    "X=ames_raw_comp.loc[:,[\"Gr Liv Area\",\"Lot Area\",\"Total Bsmt SF\"]]\n",
    "y=ames_raw_comp.loc[:,\"SalePrice\"]\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf =  LinearRegression()\n",
    "## One metric\n",
    "scores = cross_val_score(clf, X, y, cv=5,scoring=\"r2\")\n",
    "## Multiple metrics\n",
    "scoring = ['r2', 'max_error']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a97f2",
   "metadata": {},
   "source": [
    "#### PySpark\n",
    "\n",
    "[Apache Spark](https://spark.apache.org/docs/3.1.3/api/python/index.html) is a popular large data handling platform.  Over the years, they built Machine Learning capabilities in MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec5ea774",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77e1579c",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/11 21:04:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"CV_test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80457b98",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/11 21:04:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = spark.createDataFrame(\n",
    "    [(Vectors.dense([0.0]), 0.0),\n",
    "     (Vectors.dense([0.4]), 1.0),\n",
    "     (Vectors.dense([0.5]), 0.0),\n",
    "     (Vectors.dense([0.6]), 1.0),\n",
    "     (Vectors.dense([1.0]), 1.0)] * 10,\n",
    "    [\"features\", \"label\"])\n",
    "lr = LogisticRegression()\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "    parallelism=2)\n",
    "cvModel = cv.fit(dataset)\n",
    "cvModel.getNumFolds()\n",
    "cvModel.avgMetrics[0]\n",
    "evaluator.evaluate(cvModel.transform(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b8bf62f",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ae714",
   "metadata": {},
   "source": [
    "#### Resampling  using h2o\n",
    "\n",
    "On H2O cross validation is embedded in the function calling so you don't need to worry about learning a new wrapper on top of your estimator.\n",
    "https://docs.h2o.ai/h2o/latest-stable/h2o-docs/cross-validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23d989a8",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#pip install requests\n",
    "#pip install tabulate\n",
    "#pip uninstall h2o\n",
    "#pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n",
    "# load packages and data\n",
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f467085",
   "metadata": {},
   "source": [
    "##### Starting H2O\n",
    "\n",
    "To use H2O you need to instantiate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3145b8ef",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_361\"; Java(TM) SE Runtime Environment (build 1.8.0_361-b09); Java HotSpot(TM) 64-Bit Server VM (build 25.361-b09, mixed mode)\n",
      "  Starting server from /opt/homebrew/lib/python3.11/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/r8/_9frrgnx0rq_kt6_r0yvgwlc0000gn/T/tmpbl2r93zb\n",
      "  JVM stdout: /var/folders/r8/_9frrgnx0rq_kt6_r0yvgwlc0000gn/T/tmpbl2r93zb/h2o_masanaoyajima_started_from_python.out\n",
      "  JVM stderr: /var/folders/r8/_9frrgnx0rq_kt6_r0yvgwlc0000gn/T/tmpbl2r93zb/h2o_masanaoyajima_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_masanaoyajima_gs7xs1</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.529 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.3 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    22 days\n",
       "H2O_cluster_name:           H2O_from_python_masanaoyajima_gs7xs1\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.529 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.3 final\n",
       "--------------------------  ------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nthreads specifies number of threads. -1 means use all the CPU cores.\n",
    "# max_mem_size specifies the maximum amount of RAM to use.\n",
    "localH2O= h2o.init(nthreads = -1, max_mem_size=\"4g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b35a63",
   "metadata": {},
   "source": [
    "##### CV with  H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70d69efa",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7790697716207187"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the prostate dataset\n",
    "prostate = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv.zip\")\n",
    "\n",
    "# Set the predictor names and the response column name\n",
    "response = \"CAPSULE\"\n",
    "predictors = prostate.names[3:8]\n",
    "\n",
    "# Convert the response column to a factor\n",
    "prostate['CAPSULE'] = prostate['CAPSULE'].asfactor()\n",
    "\n",
    "# Train a GBM model setting nfolds to 5\n",
    "prostate_gbm = H2OGeneralizedLinearEstimator(nfolds = 5, seed = 1)\n",
    "prostate_gbm.train(x=predictors, y=response, training_frame=prostate)\n",
    "\n",
    "# AUC of cross-validated holdout predictions\n",
    "prostate_gbm.auc(xval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515ba8c",
   "metadata": {},
   "source": [
    "##### Shut down H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83132202",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE, echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_8dc7 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown(prompt =False)"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Your Name Here",
   "date": "2024-1-30",
   "output": "html_document",
   "title": "Resampling"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ],
    [
     "css",
     "css",
     "",
     ""
    ],
    [
     "Python3",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
